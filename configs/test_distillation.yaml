model:
  model_path: "weights/Tiny-ONN-0.6B-Hyper-SMoE" # Path to the student model after surgery
  base_model_name: "Qwen/Qwen3-0.6B"
  teacher_model_name: "Qwen/Qwen3-0.6B" # Teacher model for distillation
  use_torch_compile: false

data:
  dataset_name: "data/dummy_chat_data.jsonl"
  dataset_subset: null
  validation_split_percentage: 50
  max_seq_length: 128

training:
  output_dir: "output/distillation_test"
  num_train_epochs: 1
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  dataloader_num_workers: 0
  expert_learning_rate: 1.0e-5
  gate_learning_rate: 1.0e-4
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0
  lr_scheduler_warmup_steps: 1
  distillation_alpha: 0.5 # Weight for distillation loss
  distillation_temperature: 2.0 # Temperature for softmax

logging:
  log_interval: 1
  eval_interval: 2
  checkpoint_interval: 2
  rolling_checkpoint_count: 1

system:
  device: "auto"
  seed: 42
