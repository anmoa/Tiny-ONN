# 复盘：自定义 Autograd 的陷阱与回归

**日期**: 2025-07-14
**作者**: Cline

## 摘要

本文旨在复盘我们在“数字 fMRI”扫描引擎开发过程中，尝试使用自定义 `torch.autograd.Function` 方案所遇到的挑战，并阐明我们最终放弃该方案、回归更传统架构的决策过程。这是一个关于在工程实践中，优雅的理论设计与复杂系统现实之间如何取舍的典型案例。

## 1. 最初的设想：一个统一、优雅的扫描引擎

我们最初的目标是构建一个高度整合的扫描引擎。其核心思想是通过实现一个自定义的 `torch.autograd.Function` (`ScannableLinearFunction`)，并用猴子补丁（monkey-patching）的方式将其注入到模型的 `nn.Linear` 层中。

这个方案在理论上具备显著优势：

- **高度耦合**: 将数据捕获（激活与梯度）与模型的原生计算（前向与后向传播）紧密结合，无需额外的钩子管理。
- **逻辑统一**: 将生成、激活捕获、梯度计算全部封装在一个 `_generate_with_grad` 函数中，代码看似更内聚、更优雅。

我们期望通过这种方式，实现一个高效、精确且易于维护的逐 token 扫描逻辑。

## 2. 无法解决的冲突：`RuntimeError` 的泥潭

然而，在实践中，这个方案被证明是行不通的。我们陷入了一个无法解决的 `RuntimeError` 泥潭：

```
RuntimeError: The size of tensor a (1187) must match the size of tensor b (2374) at non-singleton dimension 1
```

这个错误源自模型底层的 `scaled_dot_product_attention` 函数，并且总是在生成循环的第二步（当输入序列长度发生变化时）出现。

我们为此进行了漫长而艰苦的调试，尝试了所有可能的解决方案：

- **禁用/管理 KV 缓存**: 我们尝试了禁用 KV 缓存，以及在启用时手动管理 `past_key_values`。
- **手动构建输入**: 我们放弃了 `prepare_inputs_for_generation`，尝试手动构建每一步的 `attention_mask` 和 `position_ids`。
- **防止梯度污染**: 我们意识到了 `retain_graph=True` 可能污染 KV 缓存，并引入了 `.detach()` 来净化状态。
- **咨询外部知识**: 我们向 `DeepWiki` 查询，获得了关于 `transformers` 内部复杂性的宝贵见解。

但最终，所有努力都以失败告终。无论我们如何调整生成循环的逻辑，这个底层的 `RuntimeError` 依然存在。

## 3. 根本原因诊断：侵入式修改的代价

在排除了所有上层逻辑错误后，我们得出了最终结论：**问题不在于我们的生成逻辑，而在于 `autograd.Function` 这种侵入式修改方法本身。**

`transformers` 的模型，特别是像 Qwen3 这样经过高度优化的新模型，其内部的计算图远比我们想象的要复杂。`scaled_dot_product_attention` 等核心组件很可能经过了 JIT/TorchDynamo 的编译和优化，其性能依赖于一个稳定且可预测的、由原生 PyTorch 操作构成的计算图。

我们的自定义 `autograd.Function` 作为一个 Python 对象，强行插入到这个高度优化的图中，很可能：

- **破坏了编译优化**: 打破了 JIT 编译器的优化假设。
- **改变了元数据**: 改变了张量底层的、C++ 后端所依赖的某些元数据或内存布局（如连续性）。
- **与内部机制冲突**: 与 Qwen3 模型内部处理可变序列长度的特定机制产生了无法调和的冲突。

`DeepWiki` 的回答也间接证实了这一点，它揭示了 `attention_mask` 和 `position_ids` 在模型内部被动态切片和修改的复杂性，这些都是我们从外部难以完全模拟的。

## 4. 决策：回归稳定，拥抱解耦

面对这个无法在 Python 层面解决的底层冲突，继续在当前道路上投入时间是不明智的。我们决定回归工程学的基本原则：**当一个复杂的方案失败时，回退到一个更简单、更稳定、虽然不完美但可工作的基线上。**

因此，我们做出了艰难但必要的决定：

- **放弃统一引擎**: 完全废弃基于自定义 `autograd.Function` 和猴子补丁的统一引擎方案。
- **回归解耦架构**: 回退到项目早期的、能够成功运行的解耦架构。该架构使用官方支持的、侵入性较低的 `register_forward_hook` 和 `register_full_backward_hook`，将激活捕获（前向传播）和梯度捕获（后向传播）分为两个独立的、互不干扰的步骤。

## 5. 下一步

虽然我们回退到了一个旧版本，但我们对其缺陷（梯度捕获不正确）有着清晰的认识。我们的下一个任务将不再是进行颠覆性的重构，而是在这个稳定的基线上，进行目标明确的、低风险的**增量式修复**。

这次失败的尝试为我们提供了宝贵的教训：在与高度优化的、黑盒化的复杂系统（如 `transformers` 模型）交互时，侵入性过强的修改是极其危险的。选择更稳定、更解耦、侵入性更低的方案，即使它看起来不那么“优雅”，但往往是通往成功的更可靠的路径。
