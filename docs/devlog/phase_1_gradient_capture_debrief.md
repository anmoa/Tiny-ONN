# Phase-1: 梯度捕获调试复盘

**版本:** 1.0
**日期:** 2025-07-14
**状态:** 已完成

## 1. 背景与核心问题

在 fMRI 扫描仪的开发过程中，我们的核心目标之一是在模型进行推理时，捕获其内部参数的**权重梯度 (`weight.grad`)**。这是计算“协同贡献分数 (SPS)”、理解参数功能贡献度的关键。

然而，当我们最初在资源受限的硬件上，使用 `bitsandbytes` 的 4-bit (NF4) 量化模式进行实验时，遇到了一个顽固且令人困惑的问题：**无论我们如何尝试，捕获到的梯度值始终为零。**

本次复盘旨在完整记录我们解决这一问题的侦探过程，以及最终得出的根本性结论。

## 2. 调试的曲折之路：一部假说证伪史

我们的调试过程充满了错误的假设和意外的发现，每一步都将我们引向更接近真相的地方。

### 假说 1：`model.generate()` 是罪魁祸首 (部分正确)

我们最初怀疑，`transformers` 库高度优化的 `model.generate()` 方法可能在内部使用了 `torch.no_grad()` 上下文，从而从根源上禁用了梯度计算。

- **验证方法**: 使用 `DeepWiki` 查询 `huggingface/transformers` 仓库。
- **结果**: `DeepWiki` 证实了我们的怀疑。`generate()` 方法确实被 `@torch.no_grad()` 装饰器包裹，无法用于梯度计算。
- **解决方案**: 我们重写了 `scanner/engine/custom_generate/generate.py`，用一个手动的、不带 `no_grad` 的生成循环替换了对 `model.generate()` 的调用。
- **新问题**: 即使使用了手动循环，梯度依然为零。这说明问题比我们想象的更深。

### 假说 2：参数被意外冻结 (错误)

我们接着怀疑，`device_map="auto"` 或其他模型加载机制，可能在我们将模型加载到 GPU 时，自动将参数的 `requires_grad` 属性设置为了 `False`。

- **验证方法**: 编写并执行 `debug_requires_grad.py` 脚本，遍历模型所有参数并检查其 `requires_grad` 状态。
- **结果**: 脚本输出明确显示，在 BF16 模式下，所有参数的 `requires_grad` **均为 `True`**。此假说被证伪。

### 假说 3：损失函数值为零 (部分正确)

既然计算图存在，参数也需要梯度，那为何梯度还是零？我们推断，可能是损失函数 (`loss`) 的值本身就为零或接近于零，导致其梯度也为零。在 `full_sequence` 模式下，我们的 `labels` 设置逻辑（将 prompt 部分全部掩码为 -100）可能导致在某些情况下，没有可供计算损失的 token。

- **验证方法**: 修改 `scanner/engine/backward_pass.py`，在计算损失前，**强制修改 `labels`**，引入一个故意的“错误”，以确保 `loss` 必然是一个有意义的非零值。
- **结果**:
  - **在 BF16 模式下**: 我们成功了！`DEBUG` 输出显示 `_global_grad_storage` 中捕获到了**非零的梯度值**。
  - **初步结论**: 这证明了在 BF16 模式下，我们的梯度捕获逻辑是正确的，之前的问题确实是由于损失为零导致的。

### 假说 4 (最终验证)：NF4 量化模式的内在限制

现在，我们终于可以进行最终的对照实验，以回答最初的问题：为什么 NF4 模式不行？

- **验证方法**:
  1. 将 `scripts/batch_scanner.py` 恢复为使用 `BitsAndBytesConfig` 加载 4-bit 量化模型。
  2. **保持 `backward_pass.py` 中强制产生非零损失的调试代码不变**。
  3. 运行批量扫描。
- **最终结果**: 我们没有得到零梯度，而是得到了一个更根本、更具决定性的错误：

  ```
  RuntimeError: cannot register a hook on a tensor that doesn't require gradient
  ```

  这个错误发生在 `module.weight.register_hook(...)` 这一行。

## 3. 最终结论

`RuntimeError` 无可辩驳地证明了我们的最终结论：

**`bitsandbytes` 的 4-bit (NF4) 量化，为了极致的性能优化，其 `Linear4bit` 层的权重张量 (`weight`) 在底层被设置为 `requires_grad=False`。**

这意味着，在 NF4 模式下，这些权重参数从一开始就不在计算图的追踪范围内，任何试图在其上注册梯度钩子 (`register_hook`) 的行为都会失败。我们之前在 NF4 模式下看到的全零梯度，正是这个底层机制的直接体现。

因此，**在本项目中，任何需要捕获真实权重梯度的 fMRI 扫描任务，都必须在 BF16 或 FP16 等全精度模式下进行。**

## 4. 下一步行动

基于此结论，我们的下一步行动清晰明确：

1. **整理代码库**:
    - 将本次调试过程中创建的 `debug_*.py` 和 `temp_grad_inspector.py` 等脚本，统一移动到新建的 `tools/` 目录下，作为项目永久的调试工具。
    - 从 `backward_pass.py` 中移除强制产生损失的调试代码，恢复其正常的标签掩码逻辑。
2. **配置生产环境**:
    - 确保 `scanner/app.py` 和 `scripts/batch_scanner.py` 都被设置为默认使用 BF16 模式加载模型。
3. **端到端验证**:
    - 运行一次完整的批量扫描，并使用 `tools/temp_grad_inspector.py` 检查生成的 `.mscan` 文件，最终确认在正常的 BF16 配置下，我们能够稳定地捕获到有效的、非零的梯度和激活数据。
