# Phase-0.8 层级剪枝探索最终复盘

**日期：** 2025-07-12
**状态：** 已关闭
**结论：** 失败。基于移除或跳过整个 Transformer 层的剪枝策略（无论是物理剪枝还是功能性剪枝）被证明是不可行的。

---

## 1. 背景与核心谜题

Phase-0.8 的目标是根据 PIDiff 的扫描结果，通过移除或在计算中跳过贡献度较低的 Transformer 层（主要是浅层的自注意力和深层的 MLP），来实现模型的瘦身和效率提升。

然而，所有尝试（包括物理替换模块和功能性计算旁路）都导致了模型推理输出乱码。

这引出了整个调试过程的核心谜题：为什么旧的 `commit 8309a66` 中的“功能性剪枝”实现能够正常工作，而我们后续所有基于相同剪枝策略的、理论上更完善的尝试都失败了？

## 2. 侦探过程：在错误的道路上追求正确

我们最初的探索充满了错误的假设和被证伪的理论，但每一步都让我们离真相更近。

### 2.1 初步探索：修复表层 Bug

我们首先怀疑是代码实现层面的错误：

- **残差连接/返回值问题**：我们曾怀疑 `forward` 方法的返回值结构或残差连接的实现有误。经过多次修正，使其与 `transformers` 库的定义完全一致，但乱码依旧。
- **物理剪枝的兼容性问题**：我们曾认为，在 `__init__` 中用 `nn.Identity()` 替换模块，破坏了 `transformers` 加载模型时的结构完整性，导致权重未被正确初始化。我们为此重构了整个模型定义，但这同样没有解决问题。

### 2.2 关键测试：`LayerNorm` 与“空操作”剪枝

在确认 `transformers` 库版本完全相同后，我们进行了两个关键实验：

1. **`LayerNorm` 位置修复**：我们发现，在我们的实现中，`LayerNorm` 层会随着模块一同被跳过，而 `transformers` 的原生实现是无条件执行 `LayerNorm` 的。我们“修复”了这个问题，但模型依然乱码。
2. **“空操作”剪枝**：我们将剪枝条件强制设为 `False`，让我们的功能性剪枝框架不执行任何计算旁路。**这一次，模型正常工作了。**

这无可辩驳地证明了：我们的**剪枝框架本身是正确的**，但**剪枝策略（即跳过层的决策）本身会导致模型崩溃**。

### 2.3 最终的实验与真相

既然我们的剪枝框架是正确的，为什么 `commit 8309a66` 那个应用了相同剪枝策略的旧版本能工作？

我们回到 `8309a66`，在其 `models/pruned_layers.py` 的剪枝逻辑中加入了打印语句，然后重新运行。

**真相大白：我们添加的调试日志从未被打印出来。**

`8309a66` 之所以能工作，是因为它**从未真正执行过任何剪枝操作**。`if self.prune_...` 的条件判断由于某种我们尚未探明的、代码与 `transformers` 旧版加载机制的微妙交互，结果恒为 `False`。

这个“能工作的剪枝模型”是一个安慰剂。它能工作，因为它就是那个完整的、未经修改的模型。

## 3. 结论与教训

1. **Phase-0.8 失败**：基于“跳过整个层”的剪枝策略是不可行的。Transformer 模型层与层之间高度耦合的特性，使得任何粗暴的移除都会导致模型崩溃。
2. **假设必须被验证**：这是本次探索最宝贵的教训。我们花费了大量时间去修复一个基于错误前提（“`8309a66` 的剪枝能工作”）的问题。只有通过增加 `print` 这种最直接的观测手段，我们才最终发现了真相。
3. **警惕安慰剂效应**：旧代码能“工作”可能并非因为其逻辑正确，而可能是因为其逻辑从未被真正执行。

## 4. 新的方向：回归主线

Phase-0.8 的探索到此结束。所有相关的代码（`pruner/`, `common/models/pruned_layers.py`, `common/models/func_pruned_layers.py`）将被废弃和删除。

我们将回归 `note.md` 中定义的核心技术路线，这也是 Tiny-ONN 项目的真正创新所在：

**执行基于块级（block-level）分析的纵向追踪与聚合实验。**

我们将放弃宏观的、破坏性的层级剪枝，转而进行更精细的、外科手术式的知识提取：

- **聚类分析**：对已有 `∫SPS` 分数的参数块进行特征聚类，识别功能簇。
- **专家组装**：根据聚类结果，从原始模型中提取这些参数块，组装成新的、高效的专家模块。
