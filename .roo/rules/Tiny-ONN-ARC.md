# 技术日志：Tiny-ONN-ARC 思想演化史 (v0.11.0)

本文档旨在以最高信息密度记录 `Tiny-ONN-ARC` 子项目在攻克 ARC 任务过程中的核心思想迭代、关键技术范式及其演化路径。

- **Teacher Forcing (v0.5)**
    标准的自回归训练范式。通过向模型提供完整的正确序列 `[Input, Output]`，并要求其仅预测 `Output` 的下一个 token。此方法因“暴露偏差”而失败：模型学会了依赖正确上下文的局部模式匹配（例如“前一个像素是蓝色，下一个也是”），而非真正的全局推理。在自回归生成时，微小的错误会迅速累积，导致“模式崩溃”。

- **EAVI (v0.6)**
    `Excursion-Alignment Variational Inference`（执行对齐变分推断）。一个为解决 ARC 任务中的“暴露偏差”问题，直接受 DPO 思想启发的对齐范式。它将 DPO 中基于主观“偏好”的 `(chosen, rejected)` 数据对，替换为 ARC 任务中基于客观“真值”的 `(ground_truth, generated_output)` 对。其核心是强迫模型直面**独立生成**的完整序列所带来的后果，通过与全局真值对齐，提供一个无法作弊的全局 `main_loss` 信号，在理论上等同于最小化系统的变分自由能 (VFE)。

- **OFL (v0.7)**
    `Object Finder Layer`（对象发现层）。为解决 EAVI 训练崩溃而设计。我们诊断出崩溃源于“孔径问题”：像素级路由缺乏宏观上下文。OFL 是一个置于模型前端的、非因果的全局 `DynSMHALayer`，其唯一任务是计算像素间的亲和度，将像素动态分组为“对象”，并将对象的全局上下文（原型）广播回每个像素。这实现了“感知”与“推理”的解耦，为模型提供了强大的结构归纳偏置。
