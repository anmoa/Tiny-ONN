# 技术日志：`Tiny-ONN-ARC` 的演进之路 (v0.10.0)

## 1. v0.5.0 的失败：Teacher Forcing 的陷阱

我们最初的 v0.5.0 范式，采用了标准的 Teacher Forcing。实验结果无情地揭示了这个范式的根本缺陷。模型学会的只是局部的启发式规则，在自回归生成时立刻陷入 **“模式崩溃” (Mode Collapse)**。

**结论**：`main_loss` 是一个**短视的、局部的**信号，无法迫使模型进行真正的、全局的推理。这是典型的 **“暴露偏差” (Exposure Bias)** 问题。

## 2. v0.6.0：EAVI——理论正确的对齐范式

在 v0.5.0 的失败之后，我们确立了 `EAVI (Excursion-Alignment Variational Inference)` 范式，作为解决 ARC 任务的理论正确道路。

> **为了让模型学会真正的推理，它必须在训练中直面自己独立生成完整序列（一次认知远足 Excursion）所带来的全部后果。`main_loss` 必须是基于这个完整生成序列与地面真值（Alignment）的、全局的、无法作弊的对齐信号。**

EAVI 的联合优化目标 (`main_loss` + `gating_loss`) 本质上是在最小化整个系统的变分自由能 (VFE)。

## 3. v0.7.0：架构革命——解耦“感知”与“推理”

在 v0.6.0 的 EAVI 框架下，我们遭遇了训练崩溃。日志显示，`gating_loss` 极高而 `GateAcc` 接近于零，模型陷入了“尝试预测一个随机信号”的恶性循环。

### 3.1. 核心问题：孔径问题 (Aperture Problem)

我们诊断出问题的根源：模型在进行路由决策时，缺乏足够的局部上下文。一个像素级的路由网络无法“看见”它所属的宏观形状，就像通过一个小孔观察移动的物体，无法判断其整体运动方向。

### 3.2. 架构 `v0.7.1`：对象发现层 (Object Finder Layer)

为了解决这个问题，我们引入了OFL。

1. **对象发现层 (OFL)**: 我们在模型的最前端（Embedding 之后）引入了一个特殊的、**非因果的全局 `DynSMHALayer`**。它的唯一任务，就是计算所有像素之间的亲和度，将像素动态地分组为“对象”，并将这些对象的全局上下文信息（原型）广播回给每个像素。
2. **无注意力的 `SimplifiedBlock`**: 在 OFL 完成了最困难的“结构感知”任务后，后续的 Transformer Block 不再需要 `DynSMHA` 进行特征提取。我们将其简化为只包含 `LayerNorm`、`DynMoE` 和残差连接的高效计算块。它的任务是在给定的对象上下文中，为像素选择并应用正确的“变换规则”（MoE 专家）。

这个新架构为模型提供了一个极其强大的归纳偏置：“**先理解场景的结构，再对结构中的每个部分应用规则**”，并极大地提升了计算效率。

## 4. v0.8.0：Federal EAVI

在架构 `v2.0` 的基础上，我们通过一系列严谨的 PoC 实验，最终发现了之前 EAVI 训练失败的、更深层次的原因，并确立了最终的优化范式。

### 4.1. 致命缺陷：聚合更新破坏了元学习

我们发现，标准的、对整个批次（batch）进行聚合更新的优化流程，与 EAVI 的元学习本质是根本矛盾的。

`gating_loss` 的学习目标是动态计算出的 `surprise`（即 `main_loss` 的梯度）。我们证明了：

`gating_loss( grad( mean(L_i) ) ) ≠ mean( gating_loss( grad(L_i) ) )`

- **左边（旧的聚合更新）**: 让门控网络去学习如何为一个**不存在的、平均化的“幽灵任务”**进行路由，其学习信号被严重污染。
- **右边（新的逐 `seq` 更新）**: 为门控网络提供了多个**清晰、独立、真实的**学习样本，告诉它“对于任务 A，应该这样路由；对于任务 B，应该那样路由”。

### 4.2. “逐 `seq` 更新”范式

为了保留元学习循环的**即时性 (immediacy)** 和信息保真度，我们最终确定，**必须在处理完每一个序列后，立刻执行一次完整的优化步骤**。

我们重构了训练循环，使其在一个 `for` 循环中遍历批次里的每一个序列，并**立即**执行 `backward()` 和 `optimizer.step()`。我们还通过 PoC 实验意外地发现，这种方法在我们的用例中，由于避免了对超大计算图进行 `autograd.grad`，其性能**反而比聚合更新更高**。

## 5. v0.8.x 的失败：MoE 架构的根本性错配

尽管我们拥有了联邦 EAVI 这一强大的优化范式，但 `Tiny-ONN-ARC v2.0` 在 ARC 任务上依然表现不佳，最终的 BNN 实验甚至出现了完全的模式崩溃。这迫使我们进行了一次更深层次的反思，最终发现问题不在于优化范式，而在于 MoE 架构本身的**归纳偏置**与 ARC 任务的**问题本质**之间，存在着根本性的错配。

ARC 任务的核心，不是从一个固定的“变换”库中选择一个来应用，而是需要模型**从极少的样本中归纳出全新的、抽象的符号规则，并将其组合成一个程序（Program）来执行**。

`Tiny-ONN` 的 MoE 架构，其核心是“**选择专家**”。一个专家（MLP）可能学会了一个复杂的、固定的变换（例如“将红色方块变为蓝色圆形”）。但它很难学会一个更底层的、可被灵活组合的**原子操作**（例如“向右移动一格”、“将颜色变为蓝色”）。模型试图用一个**固定的、预分化的专家库**去“套”一个需要**动态构建计算图**的程序。这就是失败的根源。

## 6. v0.9.0：从“选择专家”到“可微程序搜索”

这次反思，让我们将研究方向从“如何更有效地选择专家”，转向了一个全新的、更接近问题本质的范式：**将整个神经网络视为一个巨大的、潜在的“可微程序空间”，并通过贝叶斯推断在这个空间中进行梯度下降搜索。**

### 6.1. 贝叶斯脉冲网络 (BSNN) 作为程序空间

我们彻底放弃了 MoE 架构，转而采用一个完全由贝叶斯神经元构成的网络（例如全 MLP）。在这个新范式下：

- **神经元 ≈ 原子操作/指令 (Atomic Operations / Instructions)**：网络中的每个神经元都是一个潜在的基本计算单元。
- **权重 `(μ, σ)` ≈ 指令间的连接通路及其确定性 (Connection Pathway & its Certainty)**：每个权重分布 `(μ, σ)` 代表了从一个指令流向下一个指令的“通路”的强度（由 `μ` 体现）和信念的确定性（由 `σ` 体现）。

### 6.2. 训练即搜索，推理即执行

这个新架构彻底改变了训练和推理的含义：

1. **训练过程 (BNN Mode - 探索)**：在训练时，网络工作在 **BNN 模式**。

   - **探索 (Exploration)**：在前向传播中，通过从权重分布中**随机采样**（使用重参数化技巧），网络每次都在这个巨大的程序空间中构建一个**具体的、随机的计算图（程序实例）**。
   - **评估 (Evaluation)**：这个被采样的“程序”运行一次（例如，在 EAVI 范式下完成一次完整的自回归生成），得到一个全局的 `task_loss`。
   - **学习 (Learning)**：通过 `task_loss` 和 `KL-Divergence` 组成的 VFE 损失进行反向传播，更新**所有权重分布的参数 `(μ, σ)`**。
     - 对产生正确结果有贡献的通路，其 `μ` 会被强化，`σ` 会减小（**信念变得更确定**）。
     - 产生错误结果的通路，其 `μ` 可能会被推向 0，`σ` 会增大（**信念变得不确定或被剪枝**）。

2. **推理过程 (SNN Mode - 执行)**：在推理时（例如 `model.eval()`），网络工作在 **功能性 SNN 模式**。
   - **执行 (Execution)**：前向传播变为**确定性的**。我们不再随机采样，而是采用“**不确定性门控**”机制 (`w_effective = μ * (1 - tanh(σ))`)。
   - 信息只沿着那些在训练中被搜索到的、最“自信”的（`σ` 最小）路径流动，形成一个**涌现的、稀疏的、任务特定的计算图**。这等同于执行那个被找到的**最优程序**。

## 7. v0.10.0：从序列到图像

我们所有的失败，从梯度消失到“鹦鹉”学习，都源于一个共同的“原罪”：我们**强行将一个本质上的二维空间推理问题，塞进了一个一维自回归生成的“窄门”里**。这个错误的基本假设，导致了不可微的 `argmax` 操作的必然出现，而这个操作正是区分训练（Teacher Forcing）和推理（自回归）的万恶之源。我们之前所有的努力，无论是复杂的梯度加权还是引入强化学习，都只是在这个错误的“窄门”上裱糊，试图用越来越复杂的数学工具来弥合一个本不应该存在的裂缝。

### 7.1. 从序列到图像

我们必须回归Encoder-Decoder范式。ARC 不是一个语言任务，它是一个**图像到图像的转换任务**，自回归生成的考虑是冗余的，并行化的隐藏状态搭配自注意力和交叉注意力已足够编码全局信息。
