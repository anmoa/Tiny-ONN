# Tiny-ONN 开发计划与技术参考 v2.2

**版本：** 2.2
**日期：** 2025-07-15
**状态：** 最终版，聚焦 SLM 直接创造

## 1. 核心理论与假说

### 1.1 先验知识 (A Priori): PILF 框架的遗产

我们在前期 PILF (Predictive Integrity Learning Framework) 框架的实验中，已经得到了一个关键的、经过验证的先验知识：

- **高斯路由 + Surprise Min-K (SMK) 策略的有效性**: 实验明确表明，仅通过高斯路由机制（为每个专家定义其“领域”）和简单的 SMK 梯度更新策略（优先更新“最不惊讶”的专家），就足以在训练过程中**自发地诱导出专家功能的高度分化**，并自然地涌现出跨领域服务的**共享专家**。这证明了我们的核心思想——“让架构在训练中自适应进化”——是可行的。

### 1.2 后验目标 (A Posteriori): Tiny-ONN SLM 的验证

我们的最终目标，即需要通过构建和训练 Tiny-ONN SLM 来进行后验验证的核心科学假说，是：

- **验证 SMK 策略的规模化有效性**: 在一个从零开始训练的、包含 96 个专家的 1B 规模 SLM 上，验证“高斯路由 + SMK”架构的性能。
- **挑战 SOTA**: 最终训练出的 Tiny-ONN SLM，其性能将挑战甚至超越 `EfficientLLM-1B` 等当前同级别的 SOTA 模型，从而证明我们架构的先进性。
- **灾难性遗忘评估**: 系统性地评估模型在跨多个文本数据集（如从代码到自然语言）训练时的灾难性遗忘程度，并验证**样本重放 (Experience Replay)** 策略对缓解路由网络遗忘的有效性。

## 2. 工程实现蓝图

### 2.1 模型架构：Tiny-ONN SLM

- **模型类型**: 稀疏混合专家模型 (Sparse Mixture-of-Experts, SMoE)
- **专家数量**: 96 个独立专家
- **专家规模**: 每个专家约 10M 参数
- **路由机制**: **Token 级高斯路由 (Token-level Gaussian Routing)**。路由决策必须在每个 Token 的层面上独立做出，以实现最精细的计算资源调度。
- **核心训练策略**: **SMK (Surprise Min-K)**

### 2.2 开发路线图

1. **创建新目录**: 创建 `tiny_onn` 目录。
2. **核心架构实现**: 在 `tiny_onn/model.py` 中实现 `GaussianRouter`, `SparseMoE`, 和 `TinyOuroborosModel`。
3. **训练流程搭建**: 在 `tiny_onn/trainer.py` 中建立包含 SMK 逻辑的完整训练循环。
    - **可视化集成**: **必须**深度集成 TensorBoard，用于实时监控训练损失、专家激活频率、路由决策熵等关键指标。
    - **样本重放**: 实现一个简单的样本重放缓冲区，在训练过程中混合来自旧任务的数据。
4. **实验与评估**: 设计并执行实验，验证 SMK 策略在 SLM 规模上的有效性，评估样本重放的效果，并冲击 SOTA 性能。
