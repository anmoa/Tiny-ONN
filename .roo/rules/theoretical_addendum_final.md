# 理论附录 V3 (最终版)：定义基于对数归一化协同贡献 (ΔSC) 的 SMK Loss

## 1. 核心问题与理论修正

经过深入研讨，我们确认了之前所有技术方案的根本缺陷：**未能为门控网络提供一个理论上严谨且信号稳定的学习目标。** 单纯使用梯度范数作为 `Surprise` 的代理，理论上不完备且充满噪声。单纯使用 Z-score 进行归一化，对梯度范数中可能存在的异常值过于敏感。

为此，我们废弃所有先前的 `Surprise` 定义和 Z-score 归一化，回归到整合预测工作空间理论（IPWT）的概念——**协同贡献 (Synergistic Contribution, ΔSC)**，并采用更鲁棒的**对数归一化**方法，最终形式化定义我们的核心元学习损失 `smk_loss`。

## 2. 从 VFE 到 ΔSC：寻找最佳代理

根据自由能原理（FEP），一个高效的系统应在**最大化精确性（Accuracy）**的同时，**最小化复杂性（Complexity）**。在我们的 MoE 架构中，门控的理想任务是：将 token 路由到能够以**最低成本（Complexity）**产生**最大贡献（Accuracy）**的专家。

- **成本代理**: 我们保留**梯度范数 `G(t, e)`** 作为专家 `e` 处理 token `t` 的信念更新成本的代理。
- **贡献代理**: 我们引入**激活范数 `A(t, e)`**（专家输出的 L2 范数）作为专家 `e` 对最终预测贡献的代理。

**ΔSC** 正是这两个代理的结合，它完美地量化了每个专家的 **“性价比”** 或 **“效率”**。

## 3. 定义

### a. 贡献度矩阵的构建

在每个 MoE 层中，对于所有被激活的 `(token, expert)` 对，我们计算两个基础矩阵：

1. **激活矩阵 `M_A`**: `M_A[t, e] = ||Expert_e(h_t)||₂`
2. **梯度矩阵 `M_G`**: `M_G[t, e] = ||∇_{θ_e} L_{main}||₂` (在 `main_loss.backward()` 之后计算)

然后，我们对这两个矩阵的**所有正值元素**应用**对数归一化**，以消除尺度差异：

1. `log_M_A = torch.log1p(M_A)`
2. `log_M_G = torch.log1p(M_G)`

最终，我们得到**协同贡献矩阵 `M_ΔSC`**:

**`M_ΔSC[t, e] = log_M_A[t, e] - log_M_G[t, e]`**

### b. 目标分布的确定

对于每个 token `t`，其理想的专家选择是那个**协同贡献最高**的专家。因此，目标概率分布 `Q(e|t)` 是一个 one-hot 向量，在 `argmax_e M_ΔSC[t, e]` 的位置为 1。

### c. SMK Loss 的计算

门控元学习损失 `smk_loss` 被定义为门控网络产生的路由概率分布 `P(e|t)`（即 `softmax(router_logits)`）与理想目标分布 `Q(e|t)` 之间的交叉熵：

**`smk_loss = CrossEntropy(P(e|t), Q(e|t))`**
