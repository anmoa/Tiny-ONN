# 开发计划：Tiny-ONN SLM (Small Language Model)

**版本:** 1.0
**日期:** 2025-07-15
**状态:** 战略转向，从知识提取转向直接创造

## 1. 核心目标

废弃所有现有的扫描器（Scanner）代码和从预训练模型中提取知识的方案。我们的新目标是**从零开始，直接构建并训练一个符合 Tiny-ONN 理论的、原生的小型语言模型 (SLM)**。

## 2. 模型架构规格

- **模型类型**: 稀疏混合专家模型 (Sparse Mixture-of-Experts, SMoE)
- **专家数量**: 96 个独立专家
- **专家规模**: 每个专家约 10M (0.01B) 参数
- **总参数量**:
  - 专家参数: 96 \* 10M = 960M
  - 共享参数（注意力、Embedding 等）: 待定，预计总模型规模在 1B - 1.5B 之间
- **路由机制**: **高斯路由 (Gaussian Routing)**。这是一种新颖的路由策略，它将为每个专家学习一个高斯分布的“领域”，并根据输入与这些分布的匹配度来选择激活哪些专家。
- **核心策略**: 训练过程中将集成 **SMK² (ΔSC Max-K)** 策略，以指导专家功能分化和共享专家的涌现。

## 3. 开发路线图

### 阶段 2.1: 核心架构实现

- **任务**: 实现 Tiny-ONN 的核心 `nn.Module` 结构，包括：
  - `GaussianRouter`: 高斯路由模块。
  - `SparseMoE`: 混合专家层，能够根据路由结果动态调度专家计算。
  - `TinyOuroborosModel`: 整合注意力、MoE 层和语言模型头的顶层模型。
- **重点**: 实现高效的、可被 `torch.compile` 优化的专家调度逻辑。

### 阶段 2.2: 训练流程搭建

- **任务**: 建立完整的预训练流程，包括：
  - 数据加载与预处理。
  - 训练循环，集成 `torch.optim` 和学习率调度器。
  - 实现 SMK² 策略，以升级 PILF 中验证过的 SMK，新的梯度置零将不仅考虑梯度，也考虑激活值。
- **重点**: 确保训练流程的稳定性和可复现性。

### 阶段 2.3: 持续预训练与评估

- **任务**: 在大规模数据集上对 Tiny-ONN 进行持续预训练。
- **监控**: 使用 `ΣPI` 和 `ΩID` 工具集全程监控模型的“认知健康度”和内部信息动力学。
- **目标**: 观察并验证能力是否如理论预期般涌现，特别是专家功能的自发分化。

## 4. 后续步骤

1. **创建新目录**: 创建 `tiny_onn` 目录，用于存放新的模型和训练代码。
2. **开始编码**: 从 `tiny_onn/model.py` 开始，实现核心模型架构及 Tensorboard 集成。
