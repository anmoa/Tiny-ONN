# Tiny-ONN 开发计划 Phase-2：专家路由重组

**版本：** 1.0
**日期：** 2025-07-09
**作者：** 林睿 (Dr. Lin Rui)
**助手：** Reality Engine (RE)

## 摘要

此为 Tiny-ONN (Tiny-Optimized Neural Network) 项目的第二阶段作战纲领。本计划标志着项目战略的重大演进，我们通过一系列关键的工程权衡，旨在以更务实、更高效的方式实现核心目标。

**核心战略进化：**

1. **目标模型确认 (Target Model Confirmation)**：维持原定计划，继续使用 **Qwen1.5-4B** 作为知识提取的源模型。在全量 INT4 量化下，消费级硬件足以支持此规模模型的分析工作。
2. **数据存储加速 (Data Storage Acceleration)**：为满足对海量参数行为进行实时、高并发统计的需求，数据存储后端从 `SQLite` 全面转向 **`Redis`**。我们放弃了关系型数据库的结构化查询能力，以换取 Redis 键值存储所提供的极致读写性能和原子操作能力，这更契合本阶段大规模数据聚合与排序的核心场景。
3. **专家重组路径优化 (Expert Recomposition Path Optimization)**：为规避“自定义计算核”这一核心工程挑战，我们提出并选择了 **“结构完整性路径” (The Structural Integrity Path)**。此路径通过将分析粒度从单个参数提升至结构化单元（如 FFN 矩阵的行/列），确保了提取出的专家模块在结构上是标准的、计算上是高效的，从而可以直接利用现有的深度学习框架进行优化。

本纲领将指导我们完成从“神经考古”到“专家组装”的务实进化，确保项目在工程上高效、稳健地推进。

## 1. 知识提取阶段：从小型堡垒中提取『结构化概念』

此阶段的目标是，从 **Qwen1.5-4B** 模型中，提取出结构完整、可直接用于后续训练的功能模块。

### 1.1 核心战略调整

- **目标模型**: `Qwen/Qwen1.5-4B`。
- **数据存储**: 使用 **`Redis`**。通过 `INCRBYFLOAT` 和 `HINCRBYFLOAT` 等原子操作，实现对海量参数行为摘要的超高速、饱和式累加。
- **分析粒度**: 从**单个参数 (Scalar-level)** 提升至 **结构化单元 (Structural Unit)**。分析和聚类的对象将是 FFN 权重矩阵中的**每一列** (`d_ffn` 维度) 或**每一行** (`d_model` 维度)。

### 1.2 模型与数据准备

- **模型加载**:
  - 使用 `transformers` 和 `bitsandbytes` 库，加载 `Qwen/Qwen1.5-4B` 模型。
  - 继续强制执行 **INT4 量化** (`load_in_4bit=True`, `bnb_4bit_quant_type="nf4"`)，以确保在消费级硬件上的可行性。
- **SFT 数据集**:
  - 维持不变，继续使用 `HuggingFaceH4/ultrachat_200k` 作为“广谱显影剂”，其多样性足以激活 1.8B 模型内部的核心功能区域。
- **数据加载器**:
  - `batch_size` 必须为 **1**，以保证单样本归因分析的精确性。

### 1.3 精细化数据收集 (基于 Redis)

- **目标**: 为 Qwen1.5-4B 模型中**每一个结构化单元**（FFN矩阵的行/列）计算其行为摘要。
- **实现步骤**:
    1. **注册 Hooks**: 依然为模型中所有目标 FFN 模块注册 PyTorch Hooks。
    2. **迭代处理**: 以 `batch_size=1` 遍历 SFT 数据集。
    3. **在线聚合至 Redis**:
        - 在处理**每一个样本**后，通过 Hooks 捕获的激活与梯度张量，在 GPU 上计算其范数。
        - 将标量传回 CPU，并**立即通过 Redis 客户端**，使用 `HINCRBYFLOAT` 命令，将量化后的值累加到 Redis 中对应的哈希表字段上。
        - Redis Key 结构示例: `param:{param_name}:row:{row_index}`，字段为 `avg_act`, `avg_grad_norm`, `freq_act`。
    4. **持久化**: Redis 本身具备可配置的持久化机制（RDB/AOF），确保数据收集过程的健壮性。

### 1.4 协同贡献分数 (S_p) 计算 (基于结构化单元)

- **计算对象**: 遍历 Redis 中所有记录的**结构化单元**（行/列）。
- **核心原则**: **高激活 + 低梯度(高稳定性) + 高频次 = 高协同贡献**。此原则不变，但应用的粒度已调整为结构化单元。
- **计算过程**: 对每个结构化单元，将其在 Redis 中存储的统计摘要，通过加权公式计算出 `S_p` 分数。

### 1.5 聚类分析与专家识别 (The Structural Integrity Path)

这是本阶段计划的核心进化点。我们选择**路径一：保持结构完整性**，因为它最直接、风险最低，最符合务实的工程实践。

- **目标**: 根据 `S_p` 分数，直接从原始 FFN 矩阵中，识别并筛选出最有价值的**行列**，将它们重组成一个功能完整、结构标准的新 FFN 层。
- **实现步骤**:
    1. **特征向量构建**: 为**每一个结构化单元**（例如，FFN `gate_proj` 权重矩阵的每一列）构建特征向量。向量包含其 `S_p` 分数和行为摘要。
    2. **聚类/排序**: 对所有结构化单元（例如，`gate_proj` 的全部 `d_ffn` 个列向量）进行聚类或直接按 `S_p` 分数进行排序。
    3. **选择**: 选出 `S_p` 分数最高或处于最优簇的 **N** 个列向量（例如，N=128 或 256）。同时，在对应的 `down_proj` 矩阵中，选择与之对应的 **N** 个**行向量**。
    4. **可视化**: 依然可以使用 t-SNE 或 UMAP 对这些**结构化单元**的聚类结果进行可视化，以验证其功能分区。

### 1.6 动态提取与专家组装 (捷径)

此步骤旨在规避因处理非连续内存而导致的“自定义CUDA核”工程难题。我们现在处理的是完整的、连续的矩阵切片。

- **目标**: 根据上一步的选择结果，从 Qwen1.5-4B 模型中提取完整的行列向量，反量化至 BF16 精度，并**直接拼接**成 100 个结构标准、计算高效的专家模块。
- **实现步骤**:
    1. **索引选择 (Index Selection)**: 确定要选择的 N 个列/行向量的**索引**。
    2. **提取与拼接**:
        - 使用 `torch.index_select` 或标准的切片操作，从原始的 `gate_proj` 和 `up_proj` 权重矩阵 (`[d_model, d_ffn]`) 中，沿着 `dim=1` 抽出选定的 N 个**列**。
        - 同样，从 `down_proj` 权重矩阵 (`[d_ffn, d_model]`) 中，沿着 `dim=0` 抽出对应的 N 个**行**。
        - 将这些抽出的、更小的矩阵 (`[d_model, N]` 和 `[N, d_model]`) 直接作为新专家模块的权重。
    3. **专家组装**:
        - 创建 100 个 `TinyONNExpert` 模块。
        - 每个专家模块就是一个标准的、更小的前馈网络（FFN），其权重就是我们刚刚拼接好的密集矩阵。
        - 这些专家可以直接用标准的 `torch.nn.Linear` 加载和计算，享受所有底层硬件和框架的优化。

**结论**: 通过牺牲参数选择的最终粒度，我们换取了工程上的完全可行性。获得的专家模块“纯度”可能略有降低，但它们是**可用的、高效的、能立刻投入后续训练的**。这是一个明智且必要的工程权衡。

## 2. 梯度投影：从梯度到行为模式的直接映射

另一方面，我们可以考虑梯度投影，从而直接实现实现知识迁移：

1. **梯度捕获与缩放**：
   - 在 SFT 数据集上运行 Qwen1.5-4B 模型
   - 通过 PyTorch Hook 捕获目标参数的梯度张量 $\nabla W$
   - 应用线性缩放：$\nabla W_{\text{scaled}} = \alpha \cdot \frac{\nabla W}{||\nabla W||_2 + \epsilon}$

2. **直接投影**：
   - 将缩放后的梯度直接作为初始化增量：
     $W_{\text{small}} = W_{\text{base}} + \beta \cdot \nabla W_{\text{scaled}}$
   - 其中 $W_{\text{base}}$ 是小模型随机初始化权重，$\beta$ 为投影强度系数

3. **行为复制**：
   - 通过最小化输出差异损失实现行为对齐：
     $\mathcal{L} = \mathbb{E}_{x \sim \mathcal{D}} \left[ \text{MSE}(f_{\text{large}}(x), f_{\text{small}}(x)) \right]$

**技术优势**：

- 避免知识蒸馏的中间转换，保留原始梯度信号
- 线性操作计算高效，适合大规模参数
- 通过 $\alpha/\beta$ 系数控制知识迁移强度
- 直接复制"幽灵网络"的响应模式

**实施要点**：

- 优先在 FFN 层的 `gate_proj` 和 `down_proj` 矩阵应用
- 设置 $\alpha=0.8, \beta=0.3$ 作为初始超参数
- 使用 `torch.no_grad()` 模式确保投影不影响原始模型

## 3. 对下一阶段的启示：持续预训练

由于我们通过“结构完整性路径”获得的专家已经是标准的、密集的小型 FFN 模块，第二阶段（持续预训练）的工程难度也随之大幅降低。

- **核心任务**: 训练一个全新、随机初始化的路由网络，让它学会如何高效调度这 100 个高质量、结构标准的专家模块。
- **训练重心**: 绝大部分梯度和计算资源将集中在**路由网络**上。专家模块本身可以采用极低的学习率，甚至在初期被部分冻结，以最大程度保留其从 Qwen 模型中继承的宝贵知识结构。

我们已经成功地将一个复杂的、端到端的联合训练问题，解耦成了一个更清晰、更高效的两步过程：**首先是“发现与提取结构化概念”，然后是“适配与调度”**。项目正朝着更稳健、更可控的方向发展。
